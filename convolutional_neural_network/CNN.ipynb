{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Section I. Preparation"
      ],
      "metadata": {
        "id": "b9o7XyblV3vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "fvnt5ZUaV7N-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_TRAIN = 49000\n",
        "\n",
        "# The torchvision.transforms package provides tools for preprocessing data\n",
        "# and for performing data augmentation; here we set up a transform to\n",
        "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
        "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
        "transform = T.Compose([\n",
        "                T.ToTensor(),\n",
        "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "            ])\n",
        "\n",
        "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
        "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
        "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
        "# training set into train and val sets by passing a Sampler object to the\n",
        "# DataLoader telling how it should sample from the underlying Dataset.\n",
        "cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n",
        "                             transform=transform)\n",
        "loader_train = DataLoader(cifar10_train, batch_size=64,\n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
        "\n",
        "cifar10_val = dset.CIFAR10('./datasets', train=True, download=True,\n",
        "                           transform=transform)\n",
        "loader_val = DataLoader(cifar10_val, batch_size=64,\n",
        "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
        "\n",
        "cifar10_test = dset.CIFAR10('./datasets', train=False, download=True,\n",
        "                            transform=transform)\n",
        "loader_test = DataLoader(cifar10_test, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUXXBGVNV9O_",
        "outputId": "38987f6c-63ec-4e1a-82de-1c60e884e61d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USE_GPU = True\n",
        "\n",
        "dtype = torch.float32 # we will be using float throughout this tutorial\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# Constant to control how frequently we print train loss\n",
        "print_every = 100\n",
        "\n",
        "print('using device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfNgt3hxV__d",
        "outputId": "063cce26-d262-4d43-f6b5-812ffedf5e41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_part34(model, optimizer, epochs=1):\n",
        "    \"\"\"\n",
        "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
        "\n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "\n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        for t, (x, y) in enumerate(loader_train):\n",
        "            model.train()  # put model to training mode\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "            scores = model(x)\n",
        "            loss_function = nn.CrossEntropyLoss()\n",
        "            loss = loss_function(scores, y)\n",
        "\n",
        "            # Zero out all of the gradients for the variables which the optimizer\n",
        "            # will update.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # This is the backwards pass: compute the gradient of the loss with\n",
        "            # respect to each  parameter of the model.\n",
        "            loss.backward()\n",
        "\n",
        "            # Actually update the parameters of the model using the gradients\n",
        "            # computed by the backwards pass.\n",
        "            optimizer.step()\n",
        "\n",
        "            if t % print_every == 0:\n",
        "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "                check_accuracy_part34(loader_val, model)\n",
        "                print()"
      ],
      "metadata": {
        "id": "uxfDtL3VWIvm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy_part34(loader, model):\n",
        "    if loader.dataset.train:\n",
        "        print('Checking accuracy on validation set')\n",
        "    else:\n",
        "        print('Checking accuracy on test set')\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
      ],
      "metadata": {
        "id": "FoCQiLVKWLhL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Sequential API\n",
        "Sequential API: Two-Layer Network"
      ],
      "metadata": {
        "id": "uvnYoJ7IWSpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to wrap `flatten` function in a module in order to stack it\n",
        "# in nn.Sequential\n",
        "\n",
        "hidden_layer_size = 4000\n",
        "learning_rate = 1e-2\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(3 * 32 * 32, hidden_layer_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_layer_size, 10),\n",
        ")\n",
        "\n",
        "# you can use Nesterov momentum in optim.SGD\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
        "                     momentum=0.9, nesterov=True)\n",
        "\n",
        "train_part34(model, optimizer, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL3y_AjMWXqR",
        "outputId": "206ebc3d-cda3-457a-b568-f88e18fc8be9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, loss = 2.3080\n",
            "Checking accuracy on validation set\n",
            "Got 150 / 1000 correct (15.00)\n",
            "\n",
            "Iteration 100, loss = 1.9033\n",
            "Checking accuracy on validation set\n",
            "Got 384 / 1000 correct (38.40)\n",
            "\n",
            "Iteration 200, loss = 1.5011\n",
            "Checking accuracy on validation set\n",
            "Got 397 / 1000 correct (39.70)\n",
            "\n",
            "Iteration 300, loss = 1.5719\n",
            "Checking accuracy on validation set\n",
            "Got 383 / 1000 correct (38.30)\n",
            "\n",
            "Iteration 400, loss = 1.7038\n",
            "Checking accuracy on validation set\n",
            "Got 443 / 1000 correct (44.30)\n",
            "\n",
            "Iteration 500, loss = 1.7793\n",
            "Checking accuracy on validation set\n",
            "Got 433 / 1000 correct (43.30)\n",
            "\n",
            "Iteration 600, loss = 1.6491\n",
            "Checking accuracy on validation set\n",
            "Got 419 / 1000 correct (41.90)\n",
            "\n",
            "Iteration 700, loss = 1.9536\n",
            "Checking accuracy on validation set\n",
            "Got 434 / 1000 correct (43.40)\n",
            "\n",
            "Iteration 0, loss = 1.7938\n",
            "Checking accuracy on validation set\n",
            "Got 420 / 1000 correct (42.00)\n",
            "\n",
            "Iteration 100, loss = 1.8429\n",
            "Checking accuracy on validation set\n",
            "Got 438 / 1000 correct (43.80)\n",
            "\n",
            "Iteration 200, loss = 1.5600\n",
            "Checking accuracy on validation set\n",
            "Got 434 / 1000 correct (43.40)\n",
            "\n",
            "Iteration 300, loss = 1.6782\n",
            "Checking accuracy on validation set\n",
            "Got 454 / 1000 correct (45.40)\n",
            "\n",
            "Iteration 400, loss = 1.3739\n",
            "Checking accuracy on validation set\n",
            "Got 447 / 1000 correct (44.70)\n",
            "\n",
            "Iteration 500, loss = 1.6617\n",
            "Checking accuracy on validation set\n",
            "Got 471 / 1000 correct (47.10)\n",
            "\n",
            "Iteration 600, loss = 1.9167\n",
            "Checking accuracy on validation set\n",
            "Got 429 / 1000 correct (42.90)\n",
            "\n",
            "Iteration 700, loss = 1.7500\n",
            "Checking accuracy on validation set\n",
            "Got 478 / 1000 correct (47.80)\n",
            "\n",
            "Iteration 0, loss = 1.6455\n",
            "Checking accuracy on validation set\n",
            "Got 457 / 1000 correct (45.70)\n",
            "\n",
            "Iteration 100, loss = 2.0228\n",
            "Checking accuracy on validation set\n",
            "Got 466 / 1000 correct (46.60)\n",
            "\n",
            "Iteration 200, loss = 1.3350\n",
            "Checking accuracy on validation set\n",
            "Got 467 / 1000 correct (46.70)\n",
            "\n",
            "Iteration 300, loss = 1.5934\n",
            "Checking accuracy on validation set\n",
            "Got 453 / 1000 correct (45.30)\n",
            "\n",
            "Iteration 400, loss = 1.5342\n",
            "Checking accuracy on validation set\n",
            "Got 495 / 1000 correct (49.50)\n",
            "\n",
            "Iteration 500, loss = 1.8787\n",
            "Checking accuracy on validation set\n",
            "Got 455 / 1000 correct (45.50)\n",
            "\n",
            "Iteration 600, loss = 1.7757\n",
            "Checking accuracy on validation set\n",
            "Got 451 / 1000 correct (45.10)\n",
            "\n",
            "Iteration 700, loss = 1.6514\n",
            "Checking accuracy on validation set\n",
            "Got 466 / 1000 correct (46.60)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential API: Three-Layer ConvNet"
      ],
      "metadata": {
        "id": "ygH6gr5GWegT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = None\n",
        "optimizer = None\n",
        "\n",
        "model  = nn.Sequential(\n",
        "    # N x 3 x 32 x 32\n",
        "    nn.Conv2d(3, 32, 3, 1, 1),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    # N x 32 x 16 x 16\n",
        "    nn.Conv2d(32, 16, 3, 1, 1),\n",
        "    nn.BatchNorm2d(16),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    # N x 16 x 8 x 8\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(16*8*8, 10)\n",
        ")\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "train_part34(model, optimizer, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-Esp4xjWlqW",
        "outputId": "6d8a6130-e876-4e6b-85ff-3e0f33e55651"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, loss = 2.3929\n",
            "Checking accuracy on validation set\n",
            "Got 131 / 1000 correct (13.10)\n",
            "\n",
            "Iteration 100, loss = 1.4644\n",
            "Checking accuracy on validation set\n",
            "Got 476 / 1000 correct (47.60)\n",
            "\n",
            "Iteration 200, loss = 1.7257\n",
            "Checking accuracy on validation set\n",
            "Got 514 / 1000 correct (51.40)\n",
            "\n",
            "Iteration 300, loss = 1.1933\n",
            "Checking accuracy on validation set\n",
            "Got 530 / 1000 correct (53.00)\n",
            "\n",
            "Iteration 400, loss = 1.1519\n",
            "Checking accuracy on validation set\n",
            "Got 552 / 1000 correct (55.20)\n",
            "\n",
            "Iteration 500, loss = 1.2115\n",
            "Checking accuracy on validation set\n",
            "Got 588 / 1000 correct (58.80)\n",
            "\n",
            "Iteration 600, loss = 1.0462\n",
            "Checking accuracy on validation set\n",
            "Got 612 / 1000 correct (61.20)\n",
            "\n",
            "Iteration 700, loss = 1.2258\n",
            "Checking accuracy on validation set\n",
            "Got 611 / 1000 correct (61.10)\n",
            "\n",
            "Iteration 0, loss = 1.0449\n",
            "Checking accuracy on validation set\n",
            "Got 624 / 1000 correct (62.40)\n",
            "\n",
            "Iteration 100, loss = 1.1443\n",
            "Checking accuracy on validation set\n",
            "Got 631 / 1000 correct (63.10)\n",
            "\n",
            "Iteration 200, loss = 0.9295\n",
            "Checking accuracy on validation set\n",
            "Got 641 / 1000 correct (64.10)\n",
            "\n",
            "Iteration 300, loss = 0.9079\n",
            "Checking accuracy on validation set\n",
            "Got 642 / 1000 correct (64.20)\n",
            "\n",
            "Iteration 400, loss = 0.9317\n",
            "Checking accuracy on validation set\n",
            "Got 602 / 1000 correct (60.20)\n",
            "\n",
            "Iteration 500, loss = 1.0926\n",
            "Checking accuracy on validation set\n",
            "Got 637 / 1000 correct (63.70)\n",
            "\n",
            "Iteration 600, loss = 0.6672\n",
            "Checking accuracy on validation set\n",
            "Got 645 / 1000 correct (64.50)\n",
            "\n",
            "Iteration 700, loss = 1.0466\n",
            "Checking accuracy on validation set\n",
            "Got 641 / 1000 correct (64.10)\n",
            "\n",
            "Iteration 0, loss = 0.7470\n",
            "Checking accuracy on validation set\n",
            "Got 602 / 1000 correct (60.20)\n",
            "\n",
            "Iteration 100, loss = 0.9092\n",
            "Checking accuracy on validation set\n",
            "Got 620 / 1000 correct (62.00)\n",
            "\n",
            "Iteration 200, loss = 0.7467\n",
            "Checking accuracy on validation set\n",
            "Got 629 / 1000 correct (62.90)\n",
            "\n",
            "Iteration 300, loss = 0.9494\n",
            "Checking accuracy on validation set\n",
            "Got 646 / 1000 correct (64.60)\n",
            "\n",
            "Iteration 400, loss = 1.0335\n",
            "Checking accuracy on validation set\n",
            "Got 634 / 1000 correct (63.40)\n",
            "\n",
            "Iteration 500, loss = 1.1751\n",
            "Checking accuracy on validation set\n",
            "Got 654 / 1000 correct (65.40)\n",
            "\n",
            "Iteration 600, loss = 1.1762\n",
            "Checking accuracy on validation set\n",
            "Got 662 / 1000 correct (66.20)\n",
            "\n",
            "Iteration 700, loss = 0.9727\n",
            "Checking accuracy on validation set\n",
            "Got 669 / 1000 correct (66.90)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "id": "J9tXcuSkWud6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d76b59-93a1-4f47-dab9-b214096fba4a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             896\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "              ReLU-3           [-1, 32, 32, 32]               0\n",
            "         MaxPool2d-4           [-1, 32, 16, 16]               0\n",
            "            Conv2d-5           [-1, 16, 16, 16]           4,624\n",
            "       BatchNorm2d-6           [-1, 16, 16, 16]              32\n",
            "              ReLU-7           [-1, 16, 16, 16]               0\n",
            "         MaxPool2d-8             [-1, 16, 8, 8]               0\n",
            "           Flatten-9                 [-1, 1024]               0\n",
            "           Linear-10                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 15,866\n",
            "Trainable params: 15,866\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.92\n",
            "Params size (MB): 0.06\n",
            "Estimated Total Size (MB): 0.99\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}