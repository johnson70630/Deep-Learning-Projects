{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y97j98Q4z7Xc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2mgLa3M0Byv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4581a44d-c818-45ce-df07-543302b7863e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECfzthFg0JAx"
      },
      "outputs": [],
      "source": [
        "# Reading in our file\n",
        "raw_data = pd.read_csv('IMDBDataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fD-STdS1YrR"
      },
      "outputs": [],
      "source": [
        "# Get data & labels\n",
        "reviews = raw_data.review\n",
        "labels = raw_data.sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOm0Ite22dDv"
      },
      "outputs": [],
      "source": [
        "# Replace 'positive' with 1; 'negative' with 0\n",
        "labels.replace({'positive': 1, 'negative':0}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ok1_tvlQ2ucU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df43bae1-bf76-4db8-f495-9d6d5684cea3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1\n",
              "1        1\n",
              "2        1\n",
              "3        0\n",
              "4        1\n",
              "        ..\n",
              "49995    1\n",
              "49996    0\n",
              "49997    0\n",
              "49998    0\n",
              "49999    0\n",
              "Name: sentiment, Length: 50000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRKuY6rd3A3T"
      },
      "outputs": [],
      "source": [
        "patterns = ['<br />', '--', '.', ',', '!', '?', ')', '(', ';', ':', '*', '~', '_', \"'\", '\"']\n",
        "replacements = [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '', '']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xqN4S_p5dIu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z865Qnf56O_f"
      },
      "outputs": [],
      "source": [
        "def preprocessing(reviews, patterns, replacements):\n",
        "  lst = []\n",
        "  for i in range(len(reviews)):\n",
        "    review = reviews[i].lower()\n",
        "    for pattern, replacement in zip(patterns, replacements):\n",
        "      review = review.replace(pattern, replacement)\n",
        "    lst.append(review)\n",
        "  return lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMFvQLEJ7Jm8"
      },
      "outputs": [],
      "source": [
        "reviews = preprocessing(reviews, patterns, replacements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV8p_VRE-WWR"
      },
      "outputs": [],
      "source": [
        "num_train = 35000\n",
        "num_val = 15000\n",
        "longest_num_tokens = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gTXoaJq7EgR"
      },
      "outputs": [],
      "source": [
        "def indexing_tokens():\n",
        "  indices = {'<SOS>':0, '<EOS>': 1, '<PAD>': 2, '<UNK>': 3}\n",
        "  counter = 4\n",
        "  for i in range(num_train):\n",
        "    tokens = reviews[i].split()\n",
        "    for token in tokens:\n",
        "      if token not in indices:\n",
        "        indices[token] = counter\n",
        "        counter += 1\n",
        "  return indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jazcczJ-zfC"
      },
      "outputs": [],
      "source": [
        "def get_data(indices, longest_line_tokens, mode='train'):\n",
        "    data = []\n",
        "    Y = []\n",
        "    if mode == 'train':\n",
        "      for i in range(num_train):\n",
        "        one_train_data = []\n",
        "        y, tokens = labels[i], reviews[i].split()\n",
        "        for token in tokens:\n",
        "          one_train_data.append(indices[token])\n",
        "          if len(one_train_data) == longest_line_tokens:\n",
        "            break\n",
        "        while len(one_train_data) < longest_line_tokens:\n",
        "          one_train_data.append(indices['<PAD>'])\n",
        "        one_train_data.insert(indices['<SOS>'], 0)\n",
        "        one_train_data.append(indices['<EOS>'])\n",
        "        data.append(one_train_data)\n",
        "        Y.append(y)\n",
        "    else:\n",
        "      for i in range(num_train, num_train+num_val):\n",
        "        one_val_data = []\n",
        "        y, tokens = labels[i], reviews[i].split()\n",
        "        for token in tokens:\n",
        "          if token not in indices:\n",
        "            one_val_data.append(indices['<UNK>'])\n",
        "          else:\n",
        "            one_val_data.append(indices[token])\n",
        "          if len(one_val_data) == longest_line_tokens:\n",
        "            break\n",
        "        while len(one_val_data) < longest_line_tokens:\n",
        "          one_val_data.append(indices['<PAD>'])\n",
        "        one_val_data.insert(indices['<SOS>'], 0)\n",
        "        one_val_data.append(indices['<EOS>'])\n",
        "        data.append(one_val_data)\n",
        "        Y.append(y)\n",
        "    return data, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kuv3P6ahBQOV"
      },
      "outputs": [],
      "source": [
        "# Loading Training Data & Val Data\n",
        "indices = indexing_tokens()\n",
        "training_data, training_labels = get_data(indices, longest_num_tokens)\n",
        "val_data, val_labels = get_data(indices, longest_num_tokens, mode='val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRGUcp94M8KV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb62770-5d22-433e-a763-c7a5a29edb60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 6, 32, 33, 11, 34, 31, 35, 16, 36, 37, 38, 39, 40, 41, 5, 42, 43, 44, 45, 23, 46, 6, 47, 48, 49, 31, 25, 26, 50, 51, 52, 53, 6, 54, 55, 56, 57, 25, 52, 58, 59, 60, 30, 61, 62, 63, 64, 56, 42, 37, 26, 65, 45, 6, 66, 67, 5, 6, 47, 68, 26, 69, 16, 24, 11, 26, 6, 70, 71, 62, 6, 72, 73, 74, 75, 76, 68, 77, 78, 79, 80, 81, 82, 83, 84, 5, 6, 85, 86, 87, 6, 88, 89, 90, 91, 39, 92, 93, 94, 95, 26, 50, 96, 79, 6, 97, 98, 81, 26, 99, 62, 100, 101, 102, 103, 104, 105, 106, 107, 39, 108, 94, 109, 110, 111, 112, 113, 39, 114, 115, 22, 116, 117, 118, 119, 120, 121, 6, 122, 123, 5, 6, 52, 26, 124, 62, 6, 125, 11, 68, 126, 86, 7, 127, 128, 129, 130, 131, 132, 133, 53, 134, 135, 130, 136, 130, 137, 16, 138, 139, 140, 6, 32, 17, 119, 141, 142, 34, 31, 24, 94, 143, 68, 36, 144, 119, 145, 121, 119, 36, 146, 53, 68, 147, 24, 119, 148, 108, 119, 149, 51, 150, 53, 16, 39, 151, 152, 62, 6, 96, 153, 5, 154, 42, 50, 14, 42, 147, 155, 156, 157, 158, 19, 159, 160, 53, 51, 161, 162, 158, 163, 79, 164, 39, 165, 118, 30, 68, 166, 167, 168, 169, 162, 170, 171, 172, 85, 173, 124, 62, 174, 175, 5, 176, 177, 56, 85, 178, 13, 16, 179, 180, 181, 182, 30, 28, 26, 183, 184, 185, 186, 179, 187, 165, 45, 188, 30, 189, 190, 191, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1]\n"
          ]
        }
      ],
      "source": [
        "print(training_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLYI3st5BQ-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b5ad28-0089-429d-a11f-a881163c816f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training: 35000\n",
            "Number of validation: 15000\n",
            "Length of corpus: 122545\n"
          ]
        }
      ],
      "source": [
        "print('Number of training:', len(training_data))\n",
        "print('Number of validation:', len(val_data))\n",
        "print('Length of corpus:', len(indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5Y91DmNBWQo"
      },
      "outputs": [],
      "source": [
        "# Create tensors of train & val\n",
        "train_tensor = torch.tensor(training_data)\n",
        "train_labels_tensor = torch.tensor(training_labels)\n",
        "val_tensor = torch.tensor(val_data)\n",
        "val_labels_tensor = torch.tensor(training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-aEUFR7CDxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d27b4b6c-9b69-452d-b9e1-57d9fa7adbb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Tensor: torch.Size([35000, 502])\n",
            "Val Tensor: torch.Size([15000, 502])\n"
          ]
        }
      ],
      "source": [
        "print('Train Tensor:', train_tensor.shape)\n",
        "print('Val Tensor:', val_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V8feYElCGUp"
      },
      "outputs": [],
      "source": [
        "vocab_size = 122545\n",
        "embedding_dim = 300\n",
        "sequence_len = longest_num_tokens + 2\n",
        "output_dim = 2\n",
        "print_every = 200\n",
        "batch_size = 64\n",
        "qkv_dim = 200\n",
        "heads = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUfKUKkTivqu"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, sequence_len, embedding_dim):\n",
        "    super().__init__()\n",
        "    self.sequence_len = sequence_len\n",
        "    self.embedding_dim = embedding_dim\n",
        "  def forward(self):\n",
        "    every_other = torch.arange(0, self.embedding_dim, 2).to(device)\n",
        "    # 150\n",
        "    denominator = torch.pow(10000, every_other/self.embedding_dim)\n",
        "    # 150\n",
        "    positions = torch.arange(self.sequence_len).reshape(self.sequence_len, 1).to(device)\n",
        "    # (502, 1)\n",
        "    even = torch.sin(positions/denominator)\n",
        "    # (502, 150)\n",
        "    odd = torch.cos(positions/denominator)\n",
        "    # (502, 150)\n",
        "    stacked = torch.stack((even, odd), dim=2)\n",
        "    # (502, 150, 2)\n",
        "    return torch.flatten(stacked, 1)\n",
        "    # (502, 300)\n",
        "\n",
        "\n",
        "\n",
        "class InputEncoding(nn.Module):\n",
        "  def __init__(self, sequence_len, vocab_size, embedding_dim):\n",
        "    super().__init__()\n",
        "    self.word_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.positional_encoding = PositionalEncoding(sequence_len, embedding_dim)\n",
        "  def forward(self, x):\n",
        "    emb1 = self.word_embedding(x)\n",
        "    emb2 = self.positional_encoding()\n",
        "    return emb1 + emb2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tphZcrQqivwd"
      },
      "outputs": [],
      "source": [
        "class FeedForwardLayer(nn.Module):\n",
        "  def __init__(self, emb_size, d_out):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(emb_size, d_out)\n",
        "    self.linear2 = nn.Linear(d_out, emb_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear2(nn.functional.dropout(nn.functional.relu(self.linear1(x))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHiLtXXIiv1p"
      },
      "outputs": [],
      "source": [
        "class MultiHeadSelfAttention(nn.Module):\n",
        "  def __init__(self, embedding_dim, qkv_dim, heads):\n",
        "    super().__init__()\n",
        "    self.to_q = nn.Linear(embedding_dim, qkv_dim)\n",
        "    self.to_k = nn.Linear(embedding_dim, qkv_dim)\n",
        "    self.to_v = nn.Linear(embedding_dim, qkv_dim)\n",
        "    self.to_out = nn.Linear(qkv_dim, embedding_dim)\n",
        "\n",
        "  def forward(self, q, k, v):\n",
        "    N, sequence_len, embeeding_dim = q.shape\n",
        "    query, key, value = self.to_q(q), self.to_k(k), self.to_v(v) # NQF\n",
        "    similarity = torch.einsum('NQF,NKF->NQK', [query, key])\n",
        "    scale = embedding_dim**0.5\n",
        "    out = torch.softmax(similarity/scale, dim=2)\n",
        "    out = torch.einsum('NQK,NQF->NKF', [out, value])\n",
        "    out = self.to_out(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v39TLY4Si5Fj"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.norm = nn.LayerNorm(embedding_dim)\n",
        "  def forward(self, x, sub_layer):\n",
        "    x = sub_layer(x)\n",
        "    # print(f'after {sub_layer}: {x.shape}')\n",
        "    x = self.norm(x)\n",
        "    return x + nn.functional.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW0qIRpWi65_"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, attention: MultiHeadSelfAttention, feed_forward: FeedForwardLayer, N, seq_len, vocab_size, emb_size):\n",
        "    super().__init__()\n",
        "    self.encoding = InputEncoding(sequence_len, vocab_size, embedding_dim)\n",
        "    self.attention = attention\n",
        "    self.feed_forward = feed_forward\n",
        "    self.residual = ResidualBlock()\n",
        "    self.norm = nn.LayerNorm(embedding_dim)\n",
        "    self.out = nn.Linear(embedding_dim*sequence_len, 2)\n",
        "  def forward(self, x):\n",
        "    x = self.encoding(x)\n",
        "    x = self.residual(x, lambda x: self.attention(x, x, x))\n",
        "    # The lambda tells our self.residule to take def forward(self, x) instead of the output of forward\n",
        "    x = self.residual(x, self.feed_forward)\n",
        "    x = self.norm(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    return self.out(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Teia3SwDFIy"
      },
      "outputs": [],
      "source": [
        "model = Encoder(MultiHeadSelfAttention(embedding_dim, qkv_dim, heads), FeedForwardLayer(embedding_dim, embedding_dim), batch_size, sequence_len, vocab_size, embedding_dim)\n",
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9wKInieDM0X"
      },
      "outputs": [],
      "source": [
        "mini_trains = DataLoader(train_tensor, batch_size=batch_size)\n",
        "mini_train_labels = DataLoader(training_labels, batch_size=batch_size)\n",
        "\n",
        "mini_vals = DataLoader(val_tensor, batch_size=batch_size)\n",
        "mini_val_labels = DataLoader(val_labels, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRC2UKTODWf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957bba1e-47b7-418c-f725-6bd6bd97c948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 502])\n",
            "torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "iterator = iter(mini_trains)\n",
        "print(next(iterator).shape)\n",
        "\n",
        "iterator = iter(mini_train_labels)\n",
        "print(next(iterator).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFc1ieyZDXtY"
      },
      "outputs": [],
      "source": [
        "# Training Procedure\n",
        "def train(num_epoch, model, mini_trains, mini_train_labels, mini_vals, mini_val_labels, device, loss_function, optimizer):\n",
        "  for epoch in range(num_epoch):\n",
        "    num_iters = 0\n",
        "    for x, y in zip(mini_trains, mini_train_labels):\n",
        "      model.train()\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      scores = model(x)\n",
        "      loss = loss_function(scores, y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if num_iters % print_every == 0:\n",
        "        evaluate_predictor(model, epoch, mini_vals, mini_val_labels, device)\n",
        "      num_iters += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiRwQWQTDgzG"
      },
      "outputs": [],
      "source": [
        "# Evaluate Procedure\n",
        "def evaluate_predictor(model, epoch, mini_vals, mini_val_labels, device):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    acc_count = 0\n",
        "    for x, y in zip(mini_vals, mini_val_labels):\n",
        "      x=x.to(device)\n",
        "      y=y.to(device)\n",
        "      scores=model(x)\n",
        "      predictions=scores.max(1)[1]\n",
        "      acc = predictions.eq(y).sum().item()\n",
        "      acc_count += acc\n",
        "    print(f'Epoch[{epoch+1}] Acc: {acc_count/len(val_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsRrdh9TDkwb"
      },
      "outputs": [],
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaViXpCwDmvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a86edb-35ac-4d6d-931a-008b91861afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[1] Acc: 0.49933333333333335\n",
            "Epoch[1] Acc: 0.49766666666666665\n",
            "Epoch[1] Acc: 0.4968666666666667\n",
            "Epoch[2] Acc: 0.5040666666666667\n",
            "Epoch[2] Acc: 0.5854\n",
            "Epoch[2] Acc: 0.7829333333333334\n",
            "Epoch[3] Acc: 0.8162\n",
            "Epoch[3] Acc: 0.8292\n",
            "Epoch[3] Acc: 0.8614666666666667\n",
            "Epoch[4] Acc: 0.8513333333333334\n",
            "Epoch[4] Acc: 0.8708666666666667\n",
            "Epoch[4] Acc: 0.8329333333333333\n"
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "train(4, model, mini_trains, mini_train_labels, mini_vals, mini_val_labels, device, loss_function, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndRyHLHxDpGp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}