{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y97j98Q4z7Xc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2mgLa3M0Byv",
        "outputId": "e67577ff-8e2b-4b5a-e4d9-2af0236300e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECfzthFg0JAx",
        "outputId": "b85f554b-95a4-4e8b-c336-0c9531f96e0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0        positive\n",
            "1        positive\n",
            "2        positive\n",
            "3        negative\n",
            "4        positive\n",
            "           ...   \n",
            "49995    positive\n",
            "49996    negative\n",
            "49997    negative\n",
            "49998    negative\n",
            "49999    negative\n",
            "Name: sentiment, Length: 50000, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Reading in our file\n",
        "raw_data = pd.read_csv('IMDBDataset.csv')\n",
        "reviews = raw_data.review\n",
        "labels = raw_data.sentiment\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fD-STdS1YrR",
        "outputId": "d82b796e-7f58-481b-fa71-b5a317fa80a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        positive\n",
              "1        positive\n",
              "2        positive\n",
              "3        negative\n",
              "4        positive\n",
              "           ...   \n",
              "49995    positive\n",
              "49996    negative\n",
              "49997    negative\n",
              "49998    negative\n",
              "49999    negative\n",
              "Name: sentiment, Length: 50000, dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get data & labels\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOm0Ite22dDv"
      },
      "outputs": [],
      "source": [
        "# Replace 'positive' with 1; 'negative' with 0\n",
        "labels.replace({'positive':1, 'negative':0}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRKuY6rd3A3T"
      },
      "outputs": [],
      "source": [
        "patterns = ['<br />', '--', '.', ',', '!', '?', ')', '(', ';', ':', '*', '~', '_', \"'\", '\"']\n",
        "replacements = [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '', '']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z865Qnf56O_f"
      },
      "outputs": [],
      "source": [
        "def preprocessing(reviews, patterns, replacements):\n",
        "  lst = []\n",
        "  for i in range(len(reviews)):\n",
        "    review = reviews[i].lower()\n",
        "    for pattern, replacement in zip(patterns, replacements):\n",
        "      review = review.replace(pattern, replacement)\n",
        "    lst.append(review)\n",
        "  return lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMFvQLEJ7Jm8"
      },
      "outputs": [],
      "source": [
        "reviews = preprocessing(reviews, patterns, replacements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV8p_VRE-WWR"
      },
      "outputs": [],
      "source": [
        "num_train = 35000\n",
        "num_val = 15000\n",
        "longest_num_tokens = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gTXoaJq7EgR"
      },
      "outputs": [],
      "source": [
        "def indexing_tokens():\n",
        "  indices = {'<SOS>':0, '<EOS>':1, '<PAD>':2, '<UNK>':3}\n",
        "  index = 4\n",
        "  for i in range(num_train):\n",
        "    tokens = reviews[i].split()\n",
        "    for token in tokens:\n",
        "      if token not in indices:\n",
        "        indices[token] = index\n",
        "        index += 1\n",
        "  return indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jazcczJ-zfC"
      },
      "outputs": [],
      "source": [
        "def get_data(indices, longest_line_tokens, mode='train'):\n",
        "    data = []\n",
        "    Y = []\n",
        "    if mode == 'train':\n",
        "      for i in range(num_train):\n",
        "        one_train_data = []\n",
        "        y, tokens = labels[i], reviews[i].split()\n",
        "        for token in tokens:\n",
        "          one_train_data.append(indices[token])\n",
        "          if len(one_train_data) == longest_line_tokens:\n",
        "            break\n",
        "        while len(one_train_data) < longest_line_tokens:\n",
        "          one_train_data.append(indices['<PAD>'])\n",
        "        one_train_data.insert(0, indices['<SOS>'])\n",
        "        one_train_data.append(indices['<EOS>'])\n",
        "        data.append(one_train_data)\n",
        "        Y.append(y)\n",
        "    else:\n",
        "      for i in range(num_train, num_train+num_val):\n",
        "        one_val_data = []\n",
        "        y, tokens = labels[i], reviews[i].split()\n",
        "        for token in tokens:\n",
        "          if token in indices:\n",
        "            one_val_data.append(indices[token])\n",
        "          else:\n",
        "            one_val_data.append(indices['<UNK>'])\n",
        "          if len(one_val_data) == longest_line_tokens:\n",
        "            break\n",
        "        while len(one_val_data) < longest_line_tokens:\n",
        "          one_val_data.append(indices['<PAD>'])\n",
        "        one_val_data.insert(0, indices['<SOS>'])\n",
        "        one_val_data.append(indices['<EOS>'])\n",
        "        data.append(one_val_data)\n",
        "        Y.append(y)\n",
        "    return data, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kuv3P6ahBQOV"
      },
      "outputs": [],
      "source": [
        "# Loading Training Data & Val Data\n",
        "indices = indexing_tokens()\n",
        "training_data, training_labels = get_data(indices, longest_num_tokens)\n",
        "val_data, val_labels = get_data(indices, longest_num_tokens, mode='val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLYI3st5BQ-f",
        "outputId": "6017b809-6b3c-4184-b44b-a8fb9540a473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training: 35000\n",
            "Number of validation: 15000\n",
            "Length of corpus: 122545\n"
          ]
        }
      ],
      "source": [
        "print('Number of training:', len(training_data))\n",
        "print('Number of validation:', len(val_data))\n",
        "print('Length of corpus:', len(indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5Y91DmNBWQo"
      },
      "outputs": [],
      "source": [
        "# Create tensors of train & val\n",
        "train_tensor = torch.tensor(training_data)\n",
        "train_labels_tensor = torch.tensor(training_labels)\n",
        "val_tensor = torch.tensor(val_data)\n",
        "val_labels_tensor = torch.tensor(training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-aEUFR7CDxR",
        "outputId": "5b09aece-e35a-402b-fede-ff53c7827786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Tensor: torch.Size([35000, 252])\n",
            "Val Tensor: torch.Size([15000, 252])\n"
          ]
        }
      ],
      "source": [
        "print('Train Tensor:', train_tensor.shape)\n",
        "print('Val Tensor:', val_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V8feYElCGUp"
      },
      "outputs": [],
      "source": [
        "vocab_size = 122545\n",
        "embedding_dim = 300\n",
        "hidden_dim = 256\n",
        "sequence_len = 252\n",
        "output_dim = 2\n",
        "print_every = 400\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ute8eQpCar7"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dims, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # N x 252\n",
        "    embedded_data = self.embedding_layer(x)\n",
        "    # N x 252 x 300\n",
        "    output, (h_n, c_n) = self.lstm(embedded_data)\n",
        "    out = output[:, -1, :]\n",
        "    # out = h_n.squeeze()\n",
        "    out = self.fc(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Teia3SwDFIy"
      },
      "outputs": [],
      "source": [
        "model = MyModel(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9wKInieDM0X"
      },
      "outputs": [],
      "source": [
        "mini_trains = DataLoader(train_tensor, batch_size=batch_size)\n",
        "mini_train_labels = DataLoader(training_labels, batch_size=batch_size)\n",
        "\n",
        "mini_vals = DataLoader(val_tensor, batch_size=batch_size)\n",
        "mini_val_labels = DataLoader(val_labels, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRC2UKTODWf9",
        "outputId": "35637db6-2fe6-4af7-a923-90ebaface20d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 252])\n",
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "iterator = iter(mini_trains)\n",
        "print(next(iterator).shape)\n",
        "\n",
        "iterator = iter(mini_train_labels)\n",
        "print(next(iterator).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiRwQWQTDgzG"
      },
      "outputs": [],
      "source": [
        "# Evaluate Procedure\n",
        "def evaluate_predictor(model, epoch, mini_vals, mini_val_labels, device):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    acc_count = 0\n",
        "    for x, y in zip(mini_vals, mini_val_labels):\n",
        "      x=x.to(device)\n",
        "      y=y.to(device)\n",
        "      scores=model(x)\n",
        "      predictions=scores.max(1)[1]\n",
        "      acc = predictions.eq(y).sum().item()\n",
        "      acc_count += acc\n",
        "    print(f'Epoch[{epoch+1}] Acc: {acc_count/len(val_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFc1ieyZDXtY"
      },
      "outputs": [],
      "source": [
        "# Training Procedure\n",
        "def train(num_epoch, model, mini_trains, mini_train_labels, mini_vals, mini_val_labels, device, loss_function, optimizer):\n",
        "  for epoch in range(num_epoch):\n",
        "    num_iters = 0\n",
        "    for x, y in zip(mini_trains, mini_train_labels):\n",
        "      model.train()\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      scores = model(x)\n",
        "      loss = loss_function(scores, y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if num_iters % print_every == 0:\n",
        "        evaluate_predictor(model, epoch, mini_vals, mini_val_labels, device)\n",
        "      num_iters += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsRrdh9TDkwb"
      },
      "outputs": [],
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaViXpCwDmvp",
        "outputId": "bb1512c3-58e2-46ea-8e92-337c329d64d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch[1] Acc: 0.5026\n",
            "Epoch[1] Acc: 0.5093333333333333\n",
            "Epoch[1] Acc: 0.5006666666666667\n",
            "Epoch[2] Acc: 0.5282\n",
            "Epoch[2] Acc: 0.7037333333333333\n",
            "Epoch[2] Acc: 0.7168\n",
            "Epoch[3] Acc: 0.7915333333333333\n",
            "Epoch[3] Acc: 0.8125333333333333\n",
            "Epoch[3] Acc: 0.845\n",
            "Epoch[4] Acc: 0.8436\n",
            "Epoch[4] Acc: 0.8526666666666667\n",
            "Epoch[4] Acc: 0.8652\n",
            "Epoch[5] Acc: 0.8636666666666667\n",
            "Epoch[5] Acc: 0.8643333333333333\n",
            "Epoch[5] Acc: 0.8685333333333334\n"
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "train(5, model, mini_trains, mini_train_labels, mini_vals, mini_val_labels, device, loss_function, optimizer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
