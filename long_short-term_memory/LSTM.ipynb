{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUvgKcdC_PlB",
        "outputId": "9d912b45-d830-4b8e-cc86-88a20526469b",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Define device\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "print('Device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as T\n",
        "\n",
        "transform = T.Compose([T.ToTensor(), T.RandomAutocontrast()])"
      ],
      "metadata": {
        "id": "1nYSyXynrnbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WXam8AA_bXa"
      },
      "outputs": [],
      "source": [
        "# Load Existing Dataset\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "train_data = dset.MNIST(root=\"train\", train=True, download=True, transform=transform)\n",
        "val_data = dset.MNIST(root=\"val\", train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUYRd7bfKy7N",
        "outputId": "5f9606f7-da6f-4f7f-8d7b-70bb4ea30f14",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1725,\n",
              "           0.1843, 0.1098, 0.4549, 0.6000, 0.9961, 1.0000, 0.7647, 0.4510,\n",
              "           0.1647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.4745, 0.9451,\n",
              "           0.9922, 0.7373, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "           0.9176, 0.2549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.3569, 0.9765, 0.9922, 0.9922,\n",
              "           0.9922, 0.9922, 0.9608, 0.9725, 0.9647, 0.7412, 0.8784, 0.9922,\n",
              "           0.9922, 0.9373, 0.0824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.3686, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.8157, 0.2000, 0.2314, 0.3686, 0.1020, 0.1686, 0.9922,\n",
              "           0.9922, 0.6196, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.8627, 0.9686, 0.3176,\n",
              "           0.3647, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000, 0.3725, 0.9922,\n",
              "           0.9922, 0.9922, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.0235,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0588, 0.2863, 0.8588, 0.9922,\n",
              "           0.9922, 0.9922, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0431, 0.8980, 0.9922, 0.9922, 0.9922,\n",
              "           0.9882, 0.8078, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.4314, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "           0.8706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.4314, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "           0.9725, 0.3804, 0.4314, 0.4314, 0.2392, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.1765, 0.9137, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9922, 0.9922, 0.9922, 0.7961, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1255, 0.2000, 0.6627, 0.9922,\n",
              "           0.9922, 0.9922, 0.9922, 0.9922, 0.9843, 0.2941, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0196,\n",
              "           0.6157, 0.9490, 0.9922, 0.9922, 0.9922, 0.3647, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.5451, 0.9922, 0.9922, 0.9922, 0.3647, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0157, 0.5804, 0.9922, 0.9922, 0.9216, 0.1725, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.5373, 0.9922, 0.9922, 0.9922, 0.2549, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0353, 0.0824, 0.0824, 0.3176, 0.7961,\n",
              "           0.9882, 0.9922, 0.9922, 0.8627, 0.0706, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1373,\n",
              "           0.5490, 0.6706, 0.5059, 0.8118, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9922, 0.9922, 0.6196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.7255,\n",
              "           0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9804,\n",
              "           0.9882, 0.9529, 0.7529, 0.1804, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2549, 0.9765,\n",
              "           0.9922, 0.9922, 0.9922, 0.9882, 0.7686, 0.9490, 0.6039, 0.3373,\n",
              "           0.4667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1686,\n",
              "           0.3490, 0.3725, 0.4235, 0.9098, 0.0000, 0.1451, 0.0039, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Check Data Dimension\n",
        "val_data[500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB8ZyWY5EQTS",
        "outputId": "d0a49cda-052a-4039-9b6c-3d2a6dc5b4de",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training: 60000\n",
            "Number of validation: 10000\n"
          ]
        }
      ],
      "source": [
        "num_train = len(train_data)\n",
        "num_val = len(val_data)\n",
        "print('Number of training:', num_train)\n",
        "print('Number of validation:', num_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTFFEk6xAJ99"
      },
      "outputs": [],
      "source": [
        "# Build Model\n",
        "import torch.nn as nn\n",
        "# model = nn.Sequential(\n",
        "#     # N x 1 x 28 x 28\n",
        "#     nn.Conv2d(1, 64, 3, 1, 1),\n",
        "#     nn.BatchNorm2d(64),\n",
        "#     nn.ReLU(),\n",
        "#     nn.MaxPool2d(2, 2),\n",
        "#     # N x 64 x 14 x 14\n",
        "#     nn.Flatten(),\n",
        "#     nn.Linear(in_features=64*14*14, out_features=10)\n",
        "# )\n",
        "\n",
        "# class MyModel(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super().__init__()\n",
        "#     self.conv2d = nn.Conv2d(1, 64, 3, 1, 1)\n",
        "#     self.bn2d = nn.BatchNorm2d(64)\n",
        "#     self.fc = nn.Linear(64*14*14, 10)\n",
        "#   def forward(self, x):\n",
        "#     out = self.conv2d(x)\n",
        "#     out = self.bn2d(out)\n",
        "#     out = nn.functional.relu(out)\n",
        "#     out = nn.functional.max_pool2d(out, (2, 2))\n",
        "#     out = torch.flatten(out, 1)\n",
        "#     out = self.fc(out)\n",
        "#     return out\n",
        "\n",
        "# model = MyModel()\n",
        "\n",
        "class MyRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "  def forward(self, x):\n",
        "    x = x.squeeze()\n",
        "    output, (h_n, c_n) = self.lstm(x)\n",
        "    print(f\"output shape: {output.shape} / h_n shape: {h_n.shape}\")\n",
        "    out = output[:, -1, :]\n",
        "    # out = h_n.squeeze()\n",
        "    # out = h_n[0]\n",
        "    out = self.fc(out)\n",
        "    return out\n",
        "\n",
        "model = MyRNN(28, 64, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTg71OLVKaIO",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "# Move model to GPU\n",
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbGU1OaCAfnE"
      },
      "outputs": [],
      "source": [
        "# Create Mini-batches\n",
        "from torch.utils.data import DataLoader\n",
        "mini_trains = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "mini_vals = DataLoader(val_data, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SFsOHJABDtM"
      },
      "outputs": [],
      "source": [
        "# Training Procedure\n",
        "def train(num_epoch, model, mini_trains, mini_vals, device, loss_function, optimizer):\n",
        "  for epoch in range(num_epoch):\n",
        "    num_iters = 0\n",
        "    for x, y in mini_trains:\n",
        "      model.train()\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      scores = model(x)\n",
        "      loss = loss_function(scores, y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if num_iters % 10 == 0:\n",
        "        evaluate_predictor(model, epoch, mini_vals, device)\n",
        "      num_iters += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGjktuIUBDvf"
      },
      "outputs": [],
      "source": [
        "# Validating Procedure\n",
        "def evaluate_predictor(model, epoch, mini_vals, device):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    acc_count = 0\n",
        "    for x, y in mini_vals:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      scores=model(x)\n",
        "      predictions=scores.max(1)[1]\n",
        "      acc = predictions.eq(y).sum().item()\n",
        "      acc_count += acc\n",
        "    print(f'Epoch[{epoch+1}] Acc: {acc_count/num_val}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0V1SD_4pBDyH"
      },
      "outputs": [],
      "source": [
        "# Define loss function & optimizer\n",
        "import torch.optim as optim\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syDtanisBD0c",
        "outputId": "401c22f8-4922-4c83-85ff-bd8be76c19b7",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[1] Acc: 0.0967\n",
            "Epoch[1] Acc: 0.1964\n",
            "Epoch[1] Acc: 0.1159\n",
            "Epoch[1] Acc: 0.2172\n",
            "Epoch[1] Acc: 0.2755\n",
            "Epoch[1] Acc: 0.3694\n",
            "Epoch[1] Acc: 0.4042\n",
            "Epoch[1] Acc: 0.5359\n",
            "Epoch[1] Acc: 0.6003\n",
            "Epoch[1] Acc: 0.6274\n",
            "Epoch[1] Acc: 0.6636\n",
            "Epoch[1] Acc: 0.6996\n",
            "Epoch[1] Acc: 0.7227\n",
            "Epoch[1] Acc: 0.7429\n",
            "Epoch[1] Acc: 0.7501\n",
            "Epoch[1] Acc: 0.789\n",
            "Epoch[1] Acc: 0.7891\n",
            "Epoch[1] Acc: 0.805\n",
            "Epoch[1] Acc: 0.8257\n",
            "Epoch[1] Acc: 0.8078\n",
            "Epoch[1] Acc: 0.84\n",
            "Epoch[1] Acc: 0.8314\n",
            "Epoch[1] Acc: 0.8545\n",
            "Epoch[1] Acc: 0.8616\n",
            "Epoch[1] Acc: 0.8605\n",
            "Epoch[1] Acc: 0.852\n",
            "Epoch[1] Acc: 0.863\n",
            "Epoch[1] Acc: 0.8675\n",
            "Epoch[1] Acc: 0.8692\n",
            "Epoch[1] Acc: 0.874\n",
            "Epoch[1] Acc: 0.8814\n",
            "Epoch[1] Acc: 0.8911\n",
            "Epoch[1] Acc: 0.8959\n",
            "Epoch[1] Acc: 0.8913\n",
            "Epoch[1] Acc: 0.895\n",
            "Epoch[1] Acc: 0.9028\n",
            "Epoch[1] Acc: 0.9066\n",
            "Epoch[1] Acc: 0.9067\n",
            "Epoch[1] Acc: 0.9003\n",
            "Epoch[1] Acc: 0.9127\n",
            "Epoch[1] Acc: 0.9094\n",
            "Epoch[1] Acc: 0.905\n",
            "Epoch[1] Acc: 0.9097\n",
            "Epoch[1] Acc: 0.9103\n",
            "Epoch[1] Acc: 0.9111\n",
            "Epoch[1] Acc: 0.9103\n",
            "Epoch[1] Acc: 0.9125\n"
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "train(1, model, mini_trains, mini_vals, device, loss_function, optimizer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}